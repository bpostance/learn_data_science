{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    " - [Introductory tutorial](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
    "\n",
    "### Multi-Label Classification\n",
    " - [Sklearn package](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)\n",
    " - [Kaggle examples of common methods](https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm)\n",
    "\n",
    "### Text-Classification using word2vec\n",
    " - [word2vec tutorial](http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/)<br>\n",
    " - [deep learning turoial](https://datawarrior.wordpress.com/2016/10/12/short-text-categorization-using-deep-neural-networks-and-word-embedding-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources\n",
    " - [NLTK Reuters data](https://miguelmalvarez.com/2015/03/20/classifying-reuters-21578-collection-with-python-representing-the-data/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download Reuters Data\n",
    "## https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection\n",
    "# !curl -O https://archive.ics.uci.edu/ml/machine-learning-databases/reuters21578-mld/reuters21578.tar.gz\n",
    "# !tar xzvf reuters21578.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [20 News Group data](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train & Test data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=False)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=False)\n",
    "\n",
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {e:v for e,v in enumerate(twenty_train['target_names'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 11314)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train['data']), len(twenty_train['target']), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.baseball\n",
      "From: cubbie@garnet.berkeley.edu (                               )\n",
      "Subject: Re: Cubs behind Marlins? How?\n",
      "Article-I.D.: agate.1pt592$f9a\n",
      "Organization: University of California, Berkeley\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: garnet.berkeley.edu\n",
      "\n",
      "\n",
      "gajarsky@pilot.njin.net writes:\n",
      "\n",
      "morgan and guzman will have era's 1 run higher than last year, and\n",
      " the cubs will be idiots and not pitch harkey as much as hibbard.\n",
      " castillo won't be good (i think he's a stud pitcher)\n",
      "\n",
      "       This season so far, Morgan and Guzman helped to lead the Cubs\n",
      "       at top in ERA, even better than THE rotation at Atlanta.\n",
      "       Cubs ERA at 0.056 while Braves at 0.059. We know it is early\n",
      "       in the season, we Cubs fans have learned how to enjoy the\n",
      "       short triumph while it is still there.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "def printArticle(n):\n",
    "    global names, twenty_train\n",
    "    target = twenty_train['target'][n]\n",
    "    name = names[target]\n",
    "    doc =  twenty_train['data'][n]\n",
    "    print('{}\\n{}'.format(name,doc))\n",
    "    \n",
    "printArticle(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-c8756b08e8d0>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-c8756b08e8d0>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    .replace('[^a-zA-Z0-9 ]+', ' ', regex=True).str.lower().str.strip()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Remove non alpha-numerical chars, lowercase, strip whitespace\n",
    ".replace('[^a-zA-Z0-9 ]+', ' ', regex=True).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "[Classification reports](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample(data):\n",
    "#     X_train, X_test,\\\n",
    "#     y_train, y_test = train_test_split(data['data'],\n",
    "#                                        data['target'],\n",
    "#                                        test_size=0.5,\n",
    "#                                        stratify=data['target'])\n",
    "#     return y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "CV = CountVectorizer(strip_accents='unicode',\n",
    "                     lowercase=True,\n",
    "                     stop_words='english',)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "TF = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "# model param\n",
    "NB_params = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "             'vect__analyzer':['word','char'],\n",
    "             'tfidf__use_idf':('True'),\n",
    "             'model__alpha':(1e-1, 1e-3)}\n",
    "\n",
    "NB_pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('model', MultinomialNB())])\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=NB_pipe,\n",
    "                          param_grid=NB_params,\n",
    "                          n_jobs=-1,\n",
    "                          cv=4)\n",
    "\n",
    "%time gs_NB = gs_NB.fit(twenty_train['data'][:5000], twenty_train['target'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB-CV accuracy: 0.792\n"
     ]
    }
   ],
   "source": [
    "print(gs_NB.best_score_, gs_NB.best_params_,'\\n')\n",
    "NBcv_predict = gs_NB.predict(twenty_test['data'])\n",
    "print('NB-CV accuracy: %.3f\\n' %np.mean(NBcv_predict == twenty_test['target']))\n",
    "print(metrics.classification_report(twenty_test['target'],NBcv_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM & Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nltk\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# model param\n",
    "SVM_params = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "              'vect__analyzer':['word','char'],\n",
    "              'tfidf__use_idf':('True'),\n",
    "              'model__loss':('hinge','log'),\n",
    "              'model__alpha':(1e-2, 1e-3),\n",
    "              'model__penalty': ('l2', 'elasticnet'),\n",
    "              'model__max_iter': (50, 100)}\n",
    "\n",
    "SVM_pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('model',SGDClassifier()),])\n",
    "\n",
    "gs_SVM = GridSearchCV(SVM_pipe,\n",
    "                      param_grid=SVM_params,\n",
    "                      n_jobs=-1,\n",
    "                      cv=4)\n",
    "\n",
    "%time gs_SVM = gs_SVM.fit(twenty_train['data'][:5000], twenty_train['target'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_SVM.best_score_, gs_SVM.best_params_)\n",
    "SVMcv_predict = gs_SVM.predict(twenty_test['data'])\n",
    "print('SVM-CV accuracy: %.3f' %np.mean(SVMcv_predict, twenty_test['target']))\n",
    "print(metrics.classification_report(twenty_test['target'], SVMcv_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOG_params = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "#               'tfidf__use_idf':('True','False'),\n",
    "#               'model__alpha':(1e-1, 1e-3)}\n",
    "\n",
    "# LOG_pipe = Pipeline([('vect', CountVectorizer()),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('model',SGDClassifier(loss='log', penalty='l2',alpha=1e-3, max_iter=5, random_state=42)),])\n",
    "\n",
    "# gs_LOG = GridSearchCV(LOG_pipe, param_grid=LOG_params, n_jobs=-1)\n",
    "# gs_LOG = gs_LOG.fit(twenty_train['data'][:5000], twenty_train['target'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(gs_LOG.best_score_, gs_LOG.best_params_)\n",
    "# LOGcv_predict = gs_LOG.predict(twenty_test['data'])\n",
    "# print('LOG-CV accuracy: %.3f' %np.mean(LOGcv_predict, twenty_test['target']))\n",
    "# print(metrics.classification_report(twenty_test['target'], SVMcv_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "ANN_params = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "              'vect__analyzer':['word','char'],\n",
    "              'tfidf__use_idf':('True'),\n",
    "              'model__hidden_layer_sizes':[(3,), (3,3),(3,3,3)],\n",
    "              'model__alpha':(1e-1, 1e-3)}\n",
    "\n",
    "ANN_pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('model',MLPClassifier(tol=1e-4, max_iter=200)),])\n",
    "\n",
    "gs_ANN = GridSearchCV(ANN_pipe,\n",
    "                      param_grid=ANN_params,\n",
    "                      n_jobs=-1,\n",
    "                      cv=4)\n",
    "\n",
    "gs_ANN = gs_ANN.fit(twenty_train['data'][:5000], twenty_train['target'][:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(gs_ANN.best_score_, gs_ANN.best_params_)\n",
    "ANNcv_predict = gs_ANN.predict(twenty_test['data'])\n",
    "print('ANN-CV accuracy: %.3f' %np.mean(ANNcv_predict, twenty_test['target']))\n",
    "print(metrics.classification_report(twenty_test['target'], SVMcv_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/model_evaluation.html#multilabel-ranking-metrics\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "model = r'../'\n",
    "joblib.dump(gs_NB , model+'gs_NB_1.0.pkl') \n",
    "joblib.dump(gs_LOG, model+'gs_LOG_1.0.pkl') \n",
    "joblib.dump(gs_SVM, model+'gs_SVM_1.0.pkl') \n",
    "joblib.dump(gs_ANN, model+'gs_ANN_1.0.pkl') \n",
    "\n",
    "# trained-model = joblib.load('filename.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'doc':X_test,\n",
    "                        'target':y_test,\n",
    "                        'NB':NBcv_predict,\n",
    "                        'SVM':SVMcv_predict,\n",
    "                        'LOG':LOGcv_predict,\n",
    "                        'ANN':ANNcv_predict})\n",
    "\n",
    "results = results[['doc','target', 'NB', 'SVM', 'LOG', 'ANN']].copy()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = list(y_test.unique())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test = label_binarize(y_test, classes=classes)\n",
    "Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM = label_binarize(SVMcv_predict, classes=classes)\n",
    "SVM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1, figsize=(7,7))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i,c in enumerate(classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Test[:, i], SVM[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    axs.plot(fpr[i], tpr[i], label='%s AUC:%.2f'%(c.upper(),roc_auc[i]))\n",
    "    axs.legend()\n",
    "    axs.set_xlim(0,1)\n",
    "    axs.set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nltk]",
   "language": "python",
   "name": "conda-env-nltk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
